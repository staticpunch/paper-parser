{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e446663-0667-4dd8-893f-a7a3b2285f12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Early Testing Docling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29859045-87c1-471c-8471-7778aaa54f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6c7279-6fb6-4597-b479-69998127cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be046cc0-fc7b-4b41-b0e9-2112d4965635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docling_core.types.doc.document.DoclingDocument"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conv_result.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511c67f3-9203-4d97-888d-69af81889dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types.doc import BoundingBox, DocItem, DoclingDocument, NodeItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39837d81-2f83-4aa2-a3e5-85b8ebd2138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ae3d08-eed0-4295-bfc7-be7cd65c05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docling Parse with EasyOCR\n",
    "# ----------------------\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options.do_cell_matching = True\n",
    "pipeline_options.ocr_options.lang = [\"en\"]\n",
    "pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "    num_threads=32, device=AcceleratorDevice.AUTO\n",
    ")\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "099270e0-8cc2-4a8b-8be7-250d8aceac05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayoutOptions(create_orphan_clusters=True, keep_empty_clusters=False, model_spec=LayoutModelConfig(name='docling_layout_heron', repo_id='ds4sd/docling-layout-heron', revision='main', model_path='', supported_devices=[<AcceleratorDevice.CPU: 'cpu'>, <AcceleratorDevice.CUDA: 'cuda'>, <AcceleratorDevice.MPS: 'mps'>]), skip_cell_assignment=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_options.layout_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f9f077-929d-4c03-aea1-17f56ff0b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"/workspace/extraction/testdata/\")\n",
    "doc_paths = []\n",
    "if data_folder.exists() and data_folder.is_dir():\n",
    "    files_found = []\n",
    "    for item in data_folder.iterdir():\n",
    "        if item.is_file():\n",
    "            doc_paths.append(item)\n",
    "doc_paths = sorted(doc_paths)\n",
    "\n",
    "## Export results\n",
    "output_dir = Path(\"scratch\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adb66a09-7e23-4edb-905c-3845be20a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 04:26:21,060 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-11 04:26:21,763 - INFO - Going to convert document batch...\n",
      "2025-09-11 04:26:21,765 - INFO - Processing document 01.pdf\n",
      "2025-09-11 04:26:54,215 - INFO - Finished converting document 01.pdf in 33.93 sec.\n",
      "2025-09-11 04:26:54,225 - INFO - Document converted in 33.95 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "conv_result = doc_converter.convert(doc_paths[0])\n",
    "end_time = time.time() - start_time\n",
    "_log.info(f\"Document converted in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0946a5a0-28fa-47d4-a17d-71ea2cbf57d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_document = conv_result.document\n",
    "filtered_texts = []\n",
    "labels = []\n",
    "for element in original_document.texts:\n",
    "    labels.append(element.label)\n",
    "    \n",
    "labels = set(labels)\n",
    "# filtered_document = DoclingDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "989cb1b8-e4ba-463a-b7b4-87b1dd7eb5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<DocItemLabel.CAPTION: 'caption'>,\n",
       " <DocItemLabel.FOOTNOTE: 'footnote'>,\n",
       " <DocItemLabel.LIST_ITEM: 'list_item'>,\n",
       " <DocItemLabel.PAGE_FOOTER: 'page_footer'>,\n",
       " <DocItemLabel.PAGE_HEADER: 'page_header'>,\n",
       " <DocItemLabel.SECTION_HEADER: 'section_header'>,\n",
       " <DocItemLabel.TEXT: 'text'>}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a6cb8db-2063-4be9-bb5a-473d73220c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextItem(self_ref='#/texts/961', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.FURNITURE: 'furniture'>, label=<DocItemLabel.PAGE_FOOTER: 'page_footer'>, prov=[ProvenanceItem(page_no=31, bbox=BoundingBox(l=318.161, t=25.647022949218808, r=543.278, b=18.290022949218724, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 60))], orig='Developmental Cell 56 , 1164-1181.e1-e12, April 19, 2021 e12', text='Developmental Cell 56 , 1164-1181.e1-e12, April 19, 2021 e12', formatting=None, hyperlink=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c26b29b4-0411-4c48-a69d-99b3fbd27305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.utils.layout_postprocessor import LayoutPostprocessor\n",
    "from docling_core.types.doc import DocItemLabel\n",
    "\n",
    "# Monkey patch the confidence thresholds\n",
    "def create_custom_converter(confidence_config):\n",
    "    # Store original thresholds\n",
    "    original_thresholds = LayoutPostprocessor.CONFIDENCE_THRESHOLDS.copy()\n",
    "    \n",
    "    # Create new thresholds - set very high values for unwanted labels\n",
    "    custom_thresholds = original_thresholds.copy()\n",
    "    \n",
    "    # Set impossible thresholds (>1.0) for labels not in your config\n",
    "    for label in DocItemLabel:\n",
    "        if label not in confidence_config:\n",
    "            custom_thresholds[label] = 2.0  # Impossible threshold\n",
    "        else:\n",
    "            custom_thresholds[label] = confidence_config[label]\n",
    "    \n",
    "    # Apply the patch\n",
    "    LayoutPostprocessor.CONFIDENCE_THRESHOLDS = custom_thresholds\n",
    "    \n",
    "    # Create converter with these settings\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.do_table_structure = True\n",
    "    pipeline_options.table_structure_options.do_cell_matching = True\n",
    "    pipeline_options.ocr_options.lang = [\"en\"]\n",
    "    pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "        num_threads=32, device=AcceleratorDevice.AUTO\n",
    "    )\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Return both converter and restoration function\n",
    "    def restore_thresholds():\n",
    "        LayoutPostprocessor.CONFIDENCE_THRESHOLDS = original_thresholds\n",
    "    \n",
    "    return converter, restore_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7b9893d-c9fa-44f7-a0b2-371db8504d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 06:10:06,468 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-11 06:10:06,675 - INFO - Going to convert document batch...\n",
      "2025-09-11 06:10:06,676 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 0e1a47abb5af401bdb77d892261e0a3d\n",
      "2025-09-11 06:10:06,677 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-09-11 06:10:09,809 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-09-11 06:10:12,304 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-09-11 06:10:13,578 - INFO - Processing document 01.pdf\n",
      "2025-09-11 06:10:49,184 - INFO - Finished converting document 01.pdf in 42.72 sec.\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "confidence_config = {\n",
    "    DocItemLabel.SECTION_HEADER: 0.8,\n",
    "    DocItemLabel.TEXT: 0.95,\n",
    "    # Only include labels you want to keep\n",
    "}\n",
    "\n",
    "# Create custom converter\n",
    "custom_converter, restore_fn = create_custom_converter(confidence_config)\n",
    "\n",
    "try:\n",
    "    # Convert with custom confidence filtering\n",
    "    conv_result = custom_converter.convert(doc_paths[0])\n",
    "    \n",
    "    # Export to markdown (should work without hierarchy errors)\n",
    "    markdown_content = conv_result.document.export_to_markdown()\n",
    "    \n",
    "finally:\n",
    "    # Always restore original thresholds\n",
    "    restore_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c7d2b924-b575-42e2-ad44-7940d6f034a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dir = Path(\"testdata/debug/\")\n",
    "doc_filename = conv_result.input.file.stem\n",
    "with (debug_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(conv_result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87228239-8dcc-4e85-8534-0c4c656bbb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('scratch/01.md')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir / f\"{doc_filename}.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff87df3f-815d-46f9-a85a-04b5f72aced9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e4f3a1c724c73bb53676ae8386b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 10:31:54,103 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:31:54,139 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:31:54,140 - INFO - Processing document 01.pdf\n",
      "2025-09-09 10:32:17,571 - INFO - Finished converting document 01.pdf in 23.47 sec.\n",
      "2025-09-09 10:32:17,597 - INFO - Document converted in 23.49 seconds.\n",
      "2025-09-09 10:32:17,744 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:32:17,770 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:32:17,772 - INFO - Processing document 02.pdf\n",
      "2025-09-09 10:32:41,047 - INFO - Finished converting document 02.pdf in 23.30 sec.\n",
      "2025-09-09 10:32:41,062 - INFO - Document converted in 23.32 seconds.\n",
      "2025-09-09 10:32:41,198 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:32:41,225 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:32:41,226 - INFO - Processing document 03.pdf\n",
      "2025-09-09 10:33:08,012 - INFO - Finished converting document 03.pdf in 26.81 sec.\n",
      "2025-09-09 10:33:08,032 - INFO - Document converted in 26.83 seconds.\n",
      "2025-09-09 10:33:08,169 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:33:08,215 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:33:08,217 - INFO - Processing document 04.pdf\n",
      "2025-09-09 10:33:28,086 - INFO - Finished converting document 04.pdf in 19.92 sec.\n",
      "2025-09-09 10:33:28,112 - INFO - Document converted in 19.94 seconds.\n",
      "2025-09-09 10:33:28,310 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:33:28,494 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:33:28,495 - INFO - Processing document 05.pdf\n",
      "2025-09-09 10:33:49,953 - INFO - Finished converting document 05.pdf in 21.73 sec.\n",
      "2025-09-09 10:33:49,968 - INFO - Document converted in 21.74 seconds.\n",
      "2025-09-09 10:33:50,095 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:33:50,159 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:33:50,161 - INFO - Processing document 06.pdf\n",
      "2025-09-09 10:34:02,161 - INFO - Finished converting document 06.pdf in 12.09 sec.\n",
      "2025-09-09 10:34:02,176 - INFO - Document converted in 12.10 seconds.\n",
      "2025-09-09 10:34:02,263 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:34:02,319 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:34:02,320 - INFO - Processing document 07.pdf\n",
      "2025-09-09 10:34:30,719 - INFO - Finished converting document 07.pdf in 28.46 sec.\n",
      "2025-09-09 10:34:30,731 - INFO - Document converted in 28.47 seconds.\n",
      "2025-09-09 10:34:30,914 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:34:31,073 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:34:31,074 - INFO - Processing document 08.pdf\n",
      "2025-09-09 10:35:35,285 - INFO - Finished converting document 08.pdf in 64.38 sec.\n",
      "2025-09-09 10:35:35,303 - INFO - Document converted in 64.40 seconds.\n",
      "2025-09-09 10:35:35,617 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:35:35,964 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:35:35,965 - INFO - Processing document 09.pdf\n",
      "2025-09-09 10:35:53,530 - INFO - Finished converting document 09.pdf in 17.99 sec.\n",
      "2025-09-09 10:35:53,562 - INFO - Document converted in 18.03 seconds.\n",
      "2025-09-09 10:35:53,650 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:35:53,726 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:35:53,728 - INFO - Processing document 10.pdf\n",
      "2025-09-09 10:36:15,288 - INFO - Finished converting document 10.pdf in 21.66 sec.\n",
      "2025-09-09 10:36:15,299 - INFO - Document converted in 21.67 seconds.\n",
      "2025-09-09 10:36:15,420 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:36:15,465 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:36:15,466 - INFO - Processing document 11.pdf\n",
      "2025-09-09 10:36:27,912 - INFO - Finished converting document 11.pdf in 12.49 sec.\n",
      "2025-09-09 10:36:27,928 - INFO - Document converted in 12.51 seconds.\n",
      "2025-09-09 10:36:27,988 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:36:28,140 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:36:28,141 - INFO - Processing document 12.pdf\n",
      "2025-09-09 10:37:08,083 - INFO - Finished converting document 12.pdf in 40.11 sec.\n",
      "2025-09-09 10:37:08,091 - INFO - Document converted in 40.11 seconds.\n",
      "2025-09-09 10:37:08,606 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:37:08,802 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:37:08,803 - INFO - Processing document 13.pdf\n",
      "2025-09-09 10:37:37,719 - INFO - Finished converting document 13.pdf in 29.14 sec.\n",
      "2025-09-09 10:37:37,740 - INFO - Document converted in 29.16 seconds.\n",
      "2025-09-09 10:37:37,839 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:37:37,922 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:37:37,923 - INFO - Processing document 14.pdf\n",
      "2025-09-09 10:38:11,357 - INFO - Finished converting document 14.pdf in 33.52 sec.\n",
      "2025-09-09 10:38:11,373 - INFO - Document converted in 33.53 seconds.\n",
      "2025-09-09 10:38:11,516 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-09 10:38:12,212 - INFO - Going to convert document batch...\n",
      "2025-09-09 10:38:12,214 - INFO - Processing document 15.pdf\n",
      "2025-09-09 10:38:33,092 - INFO - Finished converting document 15.pdf in 21.62 sec.\n",
      "2025-09-09 10:38:33,106 - INFO - Document converted in 21.63 seconds.\n"
     ]
    }
   ],
   "source": [
    "for doc_path in tqdm(doc_paths):\n",
    "    start_time = time.time()\n",
    "    conv_result = doc_converter.convert(doc_path)\n",
    "    end_time = time.time() - start_time\n",
    "    _log.info(f\"Document converted in {end_time:.2f} seconds.\")\n",
    "\n",
    "    doc_filename = conv_result.input.file.stem\n",
    "    \n",
    "    # Export Deep Search document JSON format:\n",
    "    with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(json.dumps(conv_result.document.export_to_dict()))\n",
    "\n",
    "    # Export Markdown format:\n",
    "    with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(conv_result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bd1e19-7980-43d9-802b-04751903894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export results\n",
    "output_dir = Path(\"scratch\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "doc_filename = conv_result.input.file.stem\n",
    "\n",
    "# Export Deep Search document JSON format:\n",
    "with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(json.dumps(conv_result.document.export_to_dict()))\n",
    "\n",
    "# Export Text format:\n",
    "# with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "#     fp.write(conv_result.document.export_to_text())\n",
    "\n",
    "# Export Markdown format:\n",
    "# with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "#     fp.write(conv_result.document.export_to_markdown())\n",
    "\n",
    "# Export Document Tags format:\n",
    "# with (output_dir / f\"{doc_filename}.doctags\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "#     fp.write(conv_result.document.export_to_document_tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba63fc7-e4cb-4379-a9ff-a4f2d953844b",
   "metadata": {},
   "source": [
    "# 12-09-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acbd53c4-d64b-4539-bb97-0c014fbf8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "def extract_results(text):\n",
    "    \"\"\"\n",
    "    This function extracts (abstract + introduction) and results.\n",
    "    \"\"\"\n",
    "    SEP1 = r\"\\n## results?\\n\"\n",
    "    SEP2 = r\"\\n## discussion\\n\"\n",
    "\n",
    "    context, results = re.split(SEP1, text, flags=re.IGNORECASE)\n",
    "    results = re.split(SEP2, results, flags=re.IGNORECASE)[0]\n",
    "    return context, results\n",
    "\n",
    "def extract_subsections(text):\n",
    "    # \\n##          -> A newline, two hashes, and a space.\n",
    "    # (?!Figure)    -> A \"negative lookahead\". Asserts that the following text is NOT \"Figure\".\n",
    "    #                This is the key part for the exclusion.\n",
    "    # [^\\n]+        -> Matches one or more characters that are NOT a newline (the header text).\n",
    "    # \\n            -> The final newline ending the header line.\n",
    "    # wrapping the whole pattern in a capturing group (...)\n",
    "    SEP = r\"(\\n## (?!Figure)[^\\n]+\\n)\"\n",
    "    parts = re.split(SEP, text, flags=re.IGNORECASE)\n",
    "    subsections = [parts[0]]\n",
    "    for i in range(1, len(parts), 2):\n",
    "        sep = parts[i]\n",
    "        chunk = parts[i+1]\n",
    "        subsections.append(sep + chunk)\n",
    "    \n",
    "    subsections = [x.strip() for x in subsections if x.strip()]\n",
    "    \n",
    "    return subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c810bcd-179f-4b11-9962-30fc355424dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_dir = Path(\"./markdown/ocr/\")\n",
    "md_files = sorted(list(markdown_dir.glob(\"*.md\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3db96702-471e-4038-8f16-af936bf5ec3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(md_files[7], \"r\") as f:\n",
    "    # data = f.read()\n",
    "\n",
    "data = open(md_files[8], \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98ce919f-7641-4bbd-bcda-387bfdc7783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Annotating gene function from transcriptional phenotypes\n",
      "\n",
      "Previous Perturb-seq screens focused on targeted sets of perturbations, such as genes identified in forward genetic screens. Our screen targeting all expressed genes in K562 cells presented an opportunity to assess how well transcriptional phenotypes can resolve gene function when used in an unbiased manner.\n",
      "\n",
      "We focused on a subset of 1,973 perturbations that had strong transcriptional phenotypes (Figure 2A). Because related perturbations could have different magnitudes of effect, we used the correlation between mean expression profiles as a scale-invariant metric of similarity. To assess the extent to which correlated expression profiles between genetic pertur- bations indicated common function, we compared our results with two curated sources of biological relationships. First, among the 1,973 targeted genes, there were 327 protein complexes from CORUM3.0 with at least two thirds of the complex members present, representing 14,165 confirmed proteinprotein interactions (Giurgiu et al., 2019). The corresponding expression profile correlations were stronger (median r = 0.61) than the background distribution of all possible gene pairs (median r = 0.10) (Figure 2B). Second, high correlation between expression profiles was strongly associated with high STRING protein-protein interaction confidence scores (Figure 2C; Szklarczyk et al., 2019).\n",
      "\n",
      "Wenext performed an unbiased clustering of similar perturbations within the dataset. We identified 64 discrete clusters and annotated their function using CORUM, STRING, and manual searches. To visualize the dataset, we constructed a minimum distortion embedding that places genes with correlated expression profiles nearby (Figure 2D). The clusters and embedding showed clear organization by biological function spanning an array of processes including: chromatin modification; transcription; mRNA splicing, capping, polyadenylation, and turnover; nonsense-mediated decay; translation; posttranslational modification, trafficking, and degradation of proteins; central metabolism; mitochondrial transcription and translation; DNA replication; cell division; microRNA biogenesis; and major signaling pathways (Table S3).\n",
      "\n",
      "Next, we compared the similarity of transcriptional phenotypes between all three Perturb-seq datasets. For K562 cells sampled at day 8 versus day 6, both the relationships between perturbations (cophenetic correlation = 0.82) and phenotypes (median r = 0.50) were highly similar (Figures S4A and S4B). By contrast, the K562 and RPE1 datasets had more divergent relationships (cophenetic correlation = 0.37) and phenotypes (median r = 0.23) (Figures S4B-S4E).\n",
      "\n",
      "In our dataset, perturbation of many poorly annotated genes led to similar transcriptional responses to genes of known function, naturally predicting a role for these uncharacterized genes. To test these predictions, we selected ten poorly annotated genes whose perturbation response correlated with subunits and biogenesis factors of either the large or small subunit of the cytosolic ribosome (Figure S4F). This included genes that had no previous association with ribosome biogenesis ( CCDC86 , CINP , SPATA5L1 , ZNF236 , and C1orf131 ) as well as genes that had not been associated with functional defects in a particular subunit ( SPOUT1 , TMA16 , NOPCHAP1 , ABCF1 , and NEPRO ). CRISPRi-mediated depletion of nine of the ten candidate factors led to substantial defects in ribosome biogenesis, with the exception of ABCF1 , as assessed by the ratio of 28S to 18S rRNA (Figure 2E). In every case, the affected ribosomal subunit corresponded to the Perturb-seq clustering across two independent sgRNAs. Although this study was in progress, another group identified C1orf131 as a structural component of the pre-A1 small subunit processome by cryoEM, complementing our functional work (Singh et al., 2021). This validation suggests that many poorly characterized genes can be assigned functional roles through Perturb-seq, although a subset of these relationships may be explained by off-target effects (Figure S4G and S4H).\n"
     ]
    }
   ],
   "source": [
    "context, results = extract_results(data)\n",
    "subsections = extract_subsections(results)\n",
    "print(subsections[2])\n",
    "# print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
